### **학습목표**

- 각 모델들의 개괄적 이해 및 구축과정 학습.
- 파라미터를 최적화 시키는 GridSearch에 대한 이해 및 코딩작업 체화.
- 각 모델의 중요 파라미터에 대한 개괄적 이해.
- 파라미터의 변화에 따른 예측력 변화 경향성 파악.
- 최적의 모형 및 파라미터를 찾는 과정에 대한 계획 수립 및 수행.

* 원 핫 인코딩 상태 >> 범주화

 T / F 의 시리즈 리스트로 변환
 > np.select( 변환한 시리즈 리스트, 범주화할 타겟 리스트(원핫 인코딩의 컬럼들))


1. Logistic Regression

    출처 : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
    
    모델의 과적합을 방지하기 위해 모델을 정규화(일반화 시키는 방법)
    
    Lasso L1 Regulazation
      변수의 갯수를 조절하여 축소할 수 있다.
      중요성이 떨어지는 변수 먼저 조정하고, 변수 간 상관관계가 높으면 성능이 떨어진다.
      
    Ridge L2 Regulazation
      변수의 중요성을 조절하여 일반화
      중요성이 높은 변수를 먼저 조정하고, 변수 간 상관성이 높아서 모델의 성능이 떨어지지 않는다.
    
   모델 복잡도가 떨어져서 복잡한 데이터를 설명하지 못 한다.
   


2. 의사 결정 나무

 의사결정나무에서 고려해야할 criterion, min_samples_split, max_depth, min_samples_leaf, max_features
  criterion : measure 선택
  min_sample_split / max_dapth / min_samples_leaf / max_features : 모델 복잡도에 연관
  모델 복잡성을 낮추는 과정 >> Prooning
  
   복잡도가 높은 모델을 설명할 수 있지만 변수가 추가되거나 삭제 되었을 때 결과의 변동이 심하다.
   
   >> 테스트 정확도가 떨어질 수 있다.
   
  
  
 3. Random Forest
 
  - Random Forest는 아래의 Bagging과 Drop-out을 활용하여 의사결정나무의 변동성을 완화시키고 예측력을 높인 모델이다.
  - Bootstrapping: 복원추출을 통하여 샘플 구성이 조금씩 다른 여러 데이터셋을 생성해냄.
  - Aggregating: 여러 모형의 결과를 통합하여 모형의 변동성을 낮춤.
  - Drop-out: Tree를 구성할 때 변수를 일부 탈락시킴. Tree간의 correlation을 감소시켜 이 또한 모형의 변동성을 낮춤.
  
  decision tree 를 결합하여 예측력을 높혔지만, 해석력은 떨어짐
  여러 모델을 결합하였기 때문에 명확하게 결과에 대한 해석을 내놓기 어려울 수 있음
  
 4. SVM
  
  서포트 벡터 머신
  
 
 5. 인공신경망
 
   신경망 모형은 위와 같이 입력 데이터를 종합하여 결과값을 내는 구조를 가진 Perceptron을 중첩시키고 혼합시킨 구조이다. 
   아래와 같이 두 부분으로 나누어볼 수 있다.

   입력값들의 선형합 구조인 transfer function
   activation function f()

   이 때 입력값은 다른 perceptron의 출력값이 될 수 있으며 이것이 중첩되면 아래와 같이 나타날 수 있으며 이를 신경망 모형이라 한다.
    Input Layer: 입력 데이터가 위치하는 layer.
    Hidden Layer: 입력 데이터 혹은 또 다른 hidden layer의 출력값을 입력값으로 하는 perceptron이 위치하는 layer.
    Output Layer:마지막 hidden layer의 출력값을 입력값고 출력함수의 결과를 얻은 노드로 구성된 layer.
 
   복잡한 모델까지 모델을 구성할 수 있고,
   데이터의 여건이 갖춰진다면 가능성이 높은 모델이지만,
   과적합이나 모델을 수렴시키지 못할 가능성도 존재
 
 6. Boosting
 
   학습 데이터에서 여러 번 분류
   오분류 된 데이터에 가중치를 더 주고 반복함으로써 보다 적합한 결과들을 도출하고
   그 결과들을 결합하여 모델을 형성
   
   랜덤 포레스트 모델에서 발전하여, 타 모델과 차별화되는 점이 있음(다른 모델에서 구분하지 못하는 결과들을 구분해냄)
   
 
 
 
